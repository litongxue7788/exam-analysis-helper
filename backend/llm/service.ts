import OpenAI from 'openai';
import dotenv from 'dotenv';
import { LLMProvider, LLMService } from './interface'; // å¼•ç”¨ç±»å‹å®šä¹‰
import { SYSTEM_PROMPT } from './prompts';

// åŠ è½½ .env ç¯å¢ƒå˜é‡
dotenv.config();

// å®šä¹‰ä¸€ä¸ªç®€å•çš„æ¥å£æ¥æ‰¿è½½ä¸åŒå‚å•†çš„ Client
interface ProviderConfig {
  apiKey: string;
  baseURL: string;
  model: string;
}

export class LLMServiceImpl implements LLMService {
  private configs: Record<LLMProvider, ProviderConfig>;

  constructor() {
    // åˆå§‹åŒ–é…ç½®ï¼Œä»ç¯å¢ƒå˜é‡è¯»å–
    this.configs = {
      doubao: {
        apiKey: process.env.DOUBAO_API_KEY || '',
        baseURL: process.env.DOUBAO_BASE_URL || 'https://ark.cn-beijing.volces.com/api/v3',
        model: process.env.DOUBAO_MODEL_ID || '', // è±†åŒ…å¿…é¡»æŒ‡å®š Endpoint ID
      },
      aliyun: {
        apiKey: process.env.ALIYUN_API_KEY || '',
        baseURL: process.env.ALIYUN_BASE_URL || 'https://dashscope.aliyuncs.com/compatible-mode/v1',
        model: process.env.ALIYUN_MODEL_ID || 'qwen-plus',
      },
      zhipu: {
        apiKey: process.env.ZHIPU_API_KEY || '',
        baseURL: process.env.ZHIPU_BASE_URL || 'https://open.bigmodel.cn/api/paas/v4',
        model: process.env.ZHIPU_MODEL_ID || 'glm-4',
      }
    };
  }

  /**
   * æ ¸å¿ƒç”Ÿæˆæ–¹æ³•
   */
  async generateAnalysis(prompt: string, provider: LLMProvider): Promise<string> {
    const config = this.configs[provider];

    // æ£€æŸ¥é…ç½®æ˜¯å¦å®Œæ•´
    if (!config.apiKey) {
      throw new Error(`æœªé…ç½® ${provider} çš„ API Keyï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶`);
    }
    if (provider === 'doubao' && !config.model) {
      throw new Error(`æœªé…ç½®è±†åŒ…çš„ Model ID (æ¨ç†æ¥å…¥ç‚¹)ï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶`);
    }

    console.log(`ğŸš€ [LLM] æ­£åœ¨è°ƒç”¨: ${provider} | Model: ${config.model}`);

    // åˆå§‹åŒ– OpenAI å…¼å®¹å®¢æˆ·ç«¯
    const client = new OpenAI({
      apiKey: config.apiKey,
      baseURL: config.baseURL,
    });

    try {
      const response = await client.chat.completions.create({
        model: config.model,
        messages: [
          { role: 'system', content: SYSTEM_PROMPT },
          { role: 'user', content: prompt }
        ],
        temperature: 0.7, // ç¨å¾®æœ‰ç‚¹åˆ›é€ åŠ›ï¼Œä½†ä¸è¦å¤ªå‘æ•£
      });

      const content = response.choices[0]?.message?.content || '';
      return content;

    } catch (error: any) {
      console.error(`âŒ [LLM] è°ƒç”¨å¤±è´¥:`, error.message);
      // æŠ›å‡ºæ›´å‹å¥½çš„é”™è¯¯
      throw new Error(`${provider} è°ƒç”¨å¤±è´¥: ${error.message}`);
    }
  }

  getProviderConfig(provider: LLMProvider): ProviderConfig {
    return this.configs[provider];
  }

  setProviderConfig(provider: LLMProvider, config: Partial<ProviderConfig>): void {
    this.configs[provider] = {
      ...this.configs[provider],
      ...config,
    };
  }

  async generateImageAnalysis(images: string[], prompt: string, provider: LLMProvider): Promise<string> {
    const cfg = this.configs[provider];

    if (!cfg.apiKey) {
      throw new Error(`æœªé…ç½® ${provider} çš„ API Keyï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶`);
    }

    console.log(`ğŸš€ [LLM Vision] æ­£åœ¨è°ƒç”¨: ${provider} | Model: ${cfg.model}`);

    const client = new OpenAI({
      apiKey: cfg.apiKey,
      baseURL: cfg.baseURL,
    });

    // 3. æ„é€ å¤šæ¨¡æ€æ¶ˆæ¯
    const contentParts: any[] = [
        { type: "text", text: prompt }
    ];

    images.forEach(img => {
        contentParts.push({
            type: "image_url",
            image_url: {
                url: img // å‡è®¾å‰ç«¯ä¼ è¿‡æ¥çš„æ˜¯å®Œæ•´çš„ Data URI (data:image/...)
            }
        });
    });

    try {
      const response = await client.chat.completions.create({
        model: cfg.model,
        messages: [
          { role: 'system', content: SYSTEM_PROMPT },
          { role: 'user', content: contentParts }
        ],
        temperature: 0.7,
      });

      const content = response.choices[0]?.message?.content || '';
      return content;

    } catch (error: any) {
      console.error(`âŒ [LLM Vision] è°ƒç”¨å¤±è´¥:`, error.message);
      throw new Error(`${provider} Vision è°ƒç”¨å¤±è´¥: ${error.message}`);
    }
  }
}

// å¯¼å‡ºå•ä¾‹
export const llmService = new LLMServiceImpl();
